# Encoder Input å¡ä½é—®é¢˜è°ƒè¯•æŒ‡å—

## ğŸ” é—®é¢˜æè¿°

è®­ç»ƒå¡åœ¨ encoder è°ƒç”¨å¤„ï¼Œå³ä½¿å·²ç»ï¼š
- âœ… ç§»é™¤äº† CUDA åŒæ­¥ç‚¹
- âœ… è®¾ç½®äº† `sync_max_audio_length: false`

## ğŸ“Š å·²æ·»åŠ çš„è°ƒè¯•ä¿¡æ¯

### 1. **Encoder åˆå§‹åŒ–éªŒè¯**
åœ¨ `__init__` ä¸­æ·»åŠ äº†éªŒè¯ï¼Œç¡®è®¤ `sync_max_audio_length` æ˜¯å¦æ­£ç¡®è®¾ç½®ï¼š
```python
if hasattr(self.encoder, 'sync_max_audio_length'):
    print(f"[Rank {self.global_rank}] Encoder sync_max_audio_length={self.encoder.sync_max_audio_length}", flush=True)
```

### 2. **Encoder è°ƒç”¨å‰åè°ƒè¯•**
åœ¨ encoder è°ƒç”¨å‰åæ·»åŠ äº†è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼š
```python
print(f"[Rank {self.global_rank}] About to call encoder (pre_encoder path), "
      f"audio_signal.shape={processed_noisy_input_signal.shape}, "
      f"length.shape={processed_noisy_input_signal_length.shape}, "
      f"device={processed_noisy_input_signal.device}", flush=True)
encoded, encoded_len = self.encoder(...)
print(f"[Rank {self.global_rank}] Encoder call completed (pre_encoder path), "
      f"encoded.shape={encoded.shape}", flush=True)
```

## ğŸ” å¯èƒ½çš„åŸå› 

### 1. **sync_max_audio_length é…ç½®æœªç”Ÿæ•ˆ**
- æ£€æŸ¥åˆå§‹åŒ–æ—¶çš„è¾“å‡ºï¼Œç¡®è®¤ `sync_max_audio_length` æ˜¯å¦ä¸º `False`
- å¦‚æœä»ç„¶æ˜¯ `True`ï¼Œè¯´æ˜é…ç½®æ²¡æœ‰æ­£ç¡®ä¼ é€’

### 2. **Encoder å†…éƒ¨çš„ update_max_seq_length**
å³ä½¿ `sync_max_audio_length=False`ï¼Œ`update_max_seq_length` ä»ç„¶ä¼šè¢«è°ƒç”¨ï¼š
```python
# NeMo/nemo/collections/asr/modules/conformer_encoder.py:580-583
if bypass_pre_encode:
    self.update_max_seq_length(seq_length=audio_signal.size(1), device=audio_signal.device)
else:
    self.update_max_seq_length(seq_length=audio_signal.size(2), device=audio_signal.device)
```

å¦‚æœ `sync_max_audio_length=False`ï¼Œ`update_max_seq_length` ä¸­çš„ `all_reduce` ä¸ä¼šæ‰§è¡Œï¼Œä½† `set_max_audio_length` ä»ç„¶ä¼šæ‰§è¡Œï¼Œå¯èƒ½å¡åœ¨é‚£é‡Œã€‚

### 3. **DDP åŒæ­¥é—®é¢˜**
å¦‚æœæŸä¸ª rank æ²¡æœ‰åˆ°è¾¾ encoder è°ƒç”¨ï¼Œå…¶ä»– rank ä¼šåœ¨ DDP çš„æ¢¯åº¦åŒæ­¥å¤„ç­‰å¾…ã€‚

### 4. **è¾“å…¥æ•°æ®é—®é¢˜**
- è¾“å…¥å¼ é‡å¯èƒ½æœ‰ NaN æˆ– Inf å€¼
- è¾“å…¥å½¢çŠ¶å¯èƒ½ä¸ä¸€è‡´
- è¾“å…¥è®¾å¤‡å¯èƒ½ä¸ä¸€è‡´

## ğŸ› ï¸ è°ƒè¯•æ­¥éª¤

### æ­¥éª¤ 1: æ£€æŸ¥åˆå§‹åŒ–è¾“å‡º

è¿è¡Œè®­ç»ƒæ—¶ï¼ŒæŸ¥çœ‹åˆå§‹åŒ–è¾“å‡ºï¼š
```
[Rank 0] Encoder sync_max_audio_length=False
[Rank 1] Encoder sync_max_audio_length=False
...
```

å¦‚æœçœ‹åˆ° `True`ï¼Œè¯´æ˜é…ç½®æ²¡æœ‰æ­£ç¡®ä¼ é€’ã€‚

### æ­¥éª¤ 2: æ£€æŸ¥ encoder è°ƒç”¨è¾“å‡º

æŸ¥çœ‹ encoder è°ƒç”¨å‰åçš„è¾“å‡ºï¼š
```
[Rank 0] About to call encoder (no pre_encoder path), audio_signal.shape=..., device=cuda:0
[Rank 1] About to call encoder (no pre_encoder path), audio_signal.shape=..., device=cuda:1
...
```

å¦‚æœæŸä¸ª rank æ²¡æœ‰è¾“å‡º "About to call encoder"ï¼Œè¯´æ˜å®ƒåœ¨æ›´æ—©çš„åœ°æ–¹å¡ä½äº†ã€‚

### æ­¥éª¤ 3: æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ rank éƒ½åˆ°è¾¾ encoder

å¦‚æœçœ‹åˆ°æ‰€æœ‰ rank éƒ½è¾“å‡ºäº† "About to call encoder"ï¼Œä½†æ²¡æœ‰çœ‹åˆ° "Encoder call completed"ï¼Œè¯´æ˜å¡åœ¨ encoder å†…éƒ¨ã€‚

### æ­¥éª¤ 4: æ£€æŸ¥ encoder å†…éƒ¨

å¦‚æœå¡åœ¨ encoder å†…éƒ¨ï¼Œå¯èƒ½çš„åŸå› ï¼š
1. `set_max_audio_length` ä¸­çš„æ“ä½œå¡ä½
2. `pre_encode` ä¸­çš„æ“ä½œå¡ä½
3. ç¬¬ä¸€ä¸ª ConformerBlock å¡ä½

## ğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ç¡®è®¤é…ç½®æ­£ç¡®ä¼ é€’

æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦æ­£ç¡®åŠ è½½ï¼š
```python
# åœ¨ __init__ ä¸­æ·»åŠ 
print(f"[Rank {self.global_rank}] Config encoder.sync_max_audio_length={self.cfg.encoder.get('sync_max_audio_length', 'NOT SET')}", flush=True)
```

### æ–¹æ¡ˆ 2: æ£€æŸ¥è¾“å…¥æ•°æ®

åœ¨ encoder è°ƒç”¨å‰æ·»åŠ è¾“å…¥éªŒè¯ï¼š
```python
# æ£€æŸ¥ NaN/Inf
if torch.isnan(masked_signal).any() or torch.isinf(masked_signal).any():
    print(f"[Rank {self.global_rank}] WARNING: Input contains NaN or Inf!", flush=True)

# æ£€æŸ¥å½¢çŠ¶ä¸€è‡´æ€§
if masked_signal.shape[0] != processed_noisy_input_signal_length.shape[0]:
    print(f"[Rank {self.global_rank}] ERROR: Batch size mismatch!", flush=True)
```

### æ–¹æ¡ˆ 3: æ·»åŠ  DDP barrier

åœ¨ encoder è°ƒç”¨å‰æ·»åŠ  DDP barrierï¼Œç¡®ä¿æ‰€æœ‰ rank åŒæ­¥ï¼š
```python
import torch.distributed as dist

if dist.is_available() and dist.is_initialized():
    print(f"[Rank {dist.get_rank()}] Waiting for all ranks before encoder...", flush=True)
    dist.barrier()
    print(f"[Rank {dist.get_rank()}] All ranks synchronized, calling encoder...", flush=True)
```

**æ³¨æ„**ï¼šè¿™ä»ç„¶éœ€è¦æ‰€æœ‰ rank éƒ½åˆ°è¾¾ barrierï¼Œå¦‚æœæŸä¸ª rank å¡ä½ï¼Œå…¶ä»– rank ä»ç„¶ä¼šç­‰å¾…ã€‚

### æ–¹æ¡ˆ 4: æ£€æŸ¥ GPU å†…å­˜

ä½¿ç”¨ `nvidia-smi` æ£€æŸ¥ GPU å†…å­˜ä½¿ç”¨ï¼š
```bash
watch -n 1 nvidia-smi
```

å¦‚æœæŸä¸ª GPU å†…å­˜ä½¿ç”¨å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯ OOM å¯¼è‡´å¡ä½ã€‚

## ğŸ“ ä¸‹ä¸€æ­¥

1. **è¿è¡Œè®­ç»ƒå¹¶æŸ¥çœ‹è°ƒè¯•è¾“å‡º**
2. **æ ¹æ®è¾“å‡ºå®šä½å¡ä½çš„å…·ä½“ä½ç½®**
3. **æ£€æŸ¥æ‰€æœ‰ rank çš„æ—¥å¿—ï¼Œæ‰¾å‡ºå“ªä¸ª rank æ²¡æœ‰è¾“å‡º**
4. **å¦‚æœæ‰€æœ‰ rank éƒ½åˆ°è¾¾ encoder è°ƒç”¨ä½†æ²¡æœ‰å®Œæˆï¼Œæ£€æŸ¥ encoder å†…éƒ¨**

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [ENCODER_HANGING_ANALYSIS.md](ENCODER_HANGING_ANALYSIS.md) - Encoder å¡ä½é—®é¢˜åˆ†æ
- [CUDA_SYNC_FIX.md](CUDA_SYNC_FIX.md) - CUDA åŒæ­¥ä¿®å¤
- [DDP_TROUBLESHOOTING.md](DDP_TROUBLESHOOTING.md) - DDP æ•…éšœæ’é™¤

---

**æ›´æ–°æ—¥æœŸ**: 2025-01-XX  
**ç‰ˆæœ¬**: 1.0  
**çŠ¶æ€**: ğŸ”´ è°ƒè¯•ä¸­

